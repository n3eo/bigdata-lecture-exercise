version: '3'

services:
  spark-master:
    image: docker.io/bitnami/spark:3.1.2
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080'
    networks:
      - spark
  
  spark-worker:
    image: docker.io/bitnami/spark:3.1.2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    networks:
     - spark
    deploy:
      mode: replicated
      replicas: 4
  
  jupyter:
    build: 
      dockerfile: ./Dockerfile
      context: .
    ports:
      - "8888:8888"
      - "4040:4040"
    volumes: 
      - ./work:/home/jupyter/work
    environment: 
      - "SPARKMONITOR_UI_HOST=spark-master"
      - "SPARKMONITOR_UI_PORT=8080"
    networks:
      - spark

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - .env
    ports:
      - "8889:50070"
    networks:
      - spark
    
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - .env
    environment:
      SERVICE_PRECONDITION: "namenode:8020"
    networks:
      - spark
      
  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - datanode2:/hadoop/dfs/data
    env_file:
      - .env
    environment:
      SERVICE_PRECONDITION: "namenode:8020"
    networks:
      - spark

volumes:
  namenode:
  datanode:
  datanode2:
  s3data:

networks:
  spark: